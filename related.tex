%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Related Work}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% FIXME: Give another pass for dad's feedback - another sentence about each thing saying what landslide does better

Systematic exploration is a relatively young approach to concurrency verification.
Recent work has focused on theoretical aspects of the technique, on distributed systems, and in userspace in general.
Other work has focused on kernel verification apart from systematic exploration, using techniques such as data race detection and formal model verification.
Still other efforts are for testing and verification techniques that are orthogonal to systematic exploration and kernel-level testing entirely.
Here we discuss related work in all three categories.

Landslide distinguishes itself from related systematic testing tools in its field as more of an exploratory work, presenting techniques to make systematic testing compatible with kernel-level code; less so as a development on the core testing approach itself.

\section{Systematic Exploration}

Dynamic Partial Order Reduction (DPOR)\hspace{0in}\cite{dpor,sdpor,dbug-retreat,distributed-dpor} is an algorithm for reducing the state space of ``all possible thread interleavings'' by identifying independent thread transitions and pruning the redundant state spaces that result from interleaving those transitions. Landslide makes generous use of the DPOR algorithm.

dBug\cite{dbug-ssv} is a systematic testing tool which makes use of DPOR. It focuses on multithreaded userspace applications, identifying when to preempt by interposing on \texttt{libc} and \texttt{pthreads} library calls. It uses a message-passing model for inter-thread communication and for establishing a happens-before relationship between transitions. The dBug project inspired the development of Landslide.

CHESS\cite{chess} is another userspace systematic testing tool. The authors explore the insight that many races require very few forced preemptions to uncover, and develop a search strategy which prioritises thread interleavings with fewer preemptions. Landslide does not (yet) make use of this strategy, though we did find a related insight which we discuss in Section~\ref{sec:future-backwards}.

There are also several tools, such as MaceMC\cite{macemc} and MODIST\cite{modist}, which provide systematic testing frameworks for networked and distributed applications.

RacePRO\cite{racepro} is a tool based in kernel space which uncovers ``process races'' (races involving interleaving system call patterns between multiple processes) using systematic exploration of multi-process interactions in user-space. They use system calls, such as filesystem accesses, as points to explore different interleavings of concurrent code, and detect bugs which can corrupt persistent system resources.

Finally, DeMeter\cite{demeter} is a more recent tool for systematic exploration that introduces Dynamic Interface Reduction as a strategy for constraining the size of the state space, which means targetting the testing technique on only one component of the program at a time. Landslide makes use of the same general concept in its user interface (Section~\ref{sec:using}) --- it provides the user with options to constrain decision point identification to certain subsets of the kernel.

\section{Kernel-level Verification}

DataCollider\cite{datacollider} is a tool for detecting data races, a special kind of concurrency bug which involve concurrent unprotected accesses to memory that can interleave unsafely on a fine-grained level.
DataCollider uses memory access sampling, and remains largely agnostic of synchronisation operations, to find data races in the Windows 7 kernel.
In Section~\ref{sec:future-new} we discuss how systematic execution might be enhanced by integrating data race detection techniques.

Carburizer\cite{carburizer} is an effort to make imperfect kernel-level drivers work more reliably in the presence of faulty peripheral devices. They use static analysis to identify variables ``tainted'' by device input and unsafe uses thereof. Carburizer is able to transform such badly-written code to be more robust.
Kernel device drivers are a ripe breeding ground for bugs, because they are frequently written by less careful developers, and the sheer volume of code makes it difficult to rigorously review.
Due to the interrupt-driven nature of many drivers, they are also prone to concurrency bugs, which Carburizer does not address.
In Section~\ref{sec:future-drivers} we discuss the potential applicability of systematic exploration to concurrency bugs in kernel device drivers.

\subsection{New Kernel Architectures}

On the far end of the ``formality and correctness'' spectrum for kernel verification lies seL4\hspace{0in}\cite{sel4}, a microkernel fully designed and specified in Haskell and translated directly into C. Because Haskell is type-safe (strict constraints on legal program behaviour that make it easier to reason about) and pure (most code cannot have stateful side-effects), the developers of seL4 were able to formally prove the specification's correctness and the implementation's adherence to the spec.
Developing kernel code in languages and environments that enable formal complete verification, even in small components of a larger codebase, represents an admirable step towards writing correct code to begin with and avoiding many classes of bugs entirely.

Barrelfish\cite{barrelfish} is another novel kernel architecture designed with concurrency in mind. The Barrelfish kernel relies exclusively on message-passing for inter-thread communication, for increased performance on massively multi-core systems. While not a verification project, the strict limitation of inter-thread communication makes the concurrent properties of the system easy to reason about in ways that modern production kernels do not provide.
We believe Barrelfish, like seL4, is a step in the right direction for bringing better concurrent code into the world.

However, in both cases, such steps have little bearing on code that exists in the world today, and it is also important to find ways to verify more imprecisely-written code that already has bugs, which is the focus of our work.

\section{Orthogonal Testing Techniques}
\label{sec:related-orthogonal}

Research in dynamic verification has also seen other techniques apart from systematic exploration.

Data race detection is the canonical runtime concurrency verification technique. Tools such as ThreadSanitizer\cite{tsan} track synchronisation operations and happens-before relationships to identify unsafe concurrent memory accesses. Such accesses, called ``data races'', might not necessarily cause incorrect behaviour, but are usually warning indicators of such, and represent bad coding practice in any case.

Symbolic execution\cite{symbolic,symbolic-disks} is a technique for testing programs by abstractly interpreting symbols and operations within a program, rather than directly executing its compiled code, which grants the ability to analyse conditional statements and cause-effect relationships among certain code paths.
Tools such as KLEE\cite{klee} and projects such as Automated Exploit Generation\cite{aeg} demonstrate the effectiveness of symbolic execution in dynamic verification.

There has also been recent research in searching for which conditions, among a known set of conditions associated with a buggy behaviour, are actually necessary to cause bugs to arise\cite{dag-mining}. Such strategies are helpful because even once a bug is exposed, it can be difficult to determine what specifically went wrong.

We discuss the possibility of integrating each of these orthogonal techniques into a testing framework such as Landslide in Section~\ref{sec:future-new}.

Deterministic multithreading is a different technique for dealing with concurrency bugs which focuses on avoiding them when running production code rather than trying to expose them during testing. Deterministic multithreading tools, such as Kendo\cite{kendo}, Peregrine\hspace{0in}\cite{peregrine}, and DThreads\cite{dthreads}, analyse the execution of a concurrent system, compute particular scheduling patterns which will not produce buggy behaviours, and force the system to follow those schedules while maintaining good parallel performance.
Deterministic multithreading serves a different purpose than systematic exploration: it aims to ensure that code already running in the real world does not encounter concurrency bugs even though they might exist, while our goals are instead to uncover such bugs and help fix them beforehand.

% vim: ft=tex
